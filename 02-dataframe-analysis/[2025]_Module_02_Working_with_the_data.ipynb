{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de7d12ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (487512650.py, line 477)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 477\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install pyarrow\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ### Question 1: [IPO] Withdrawn IPOs by Company Type\n",
    "# \n",
    "# **What is the total withdrawn IPO value (in $ millions) for the company class with the highest total withdrawal value?**\n",
    "# \n",
    "# From the withdrawn IPO list ([stockanalysis.com/ipos/withdrawn](https://stockanalysis.com/ipos/withdrawn/)), collect and process the data to find out which company type saw the most withdrawn IPO value.\n",
    "# \n",
    "# #### Steps:\n",
    "# 1. Use pandas.read_html() with the URL above to load the IPO withdrawal table into a DataFrame. \n",
    "#    *It is a similar process to Code Snippet 1 discussed at the livestream.*    You should get **99 entries**. \n",
    "# 2. Create a new column called Company Class, categorizing company names based on patterns like:\n",
    "#    - ‚ÄúAcquisition Corp‚Äù or ‚ÄúAcquisition Corporation‚Äù ‚Üí Acq.Corp\n",
    "#    - ‚ÄúInc‚Äù or ‚ÄúIncorporated‚Äù ‚Üí Inc\n",
    "#    - ‚ÄúGroup‚Äù ‚Üí Group\n",
    "#    - ‚ÄúLtd‚Äù or ‚ÄúLimited‚Äù ‚Üí Limited\n",
    "#    - ‚ÄúHoldings‚Äù ‚Üí Holdings\n",
    "#    - Others ‚Üí Other\n",
    "# \n",
    "#   *  Order: Please follow the listed order of classes and assign the first matched value (e.g., for 'shenni holdings limited', you assign the 'Limited' class).\n",
    "# \n",
    "#   * Hint: make your function more robust by converting names to lowercase and splitting into words before matching patterns.\n",
    "# \n",
    "# 3. Define a new field Avg. price by parsing the Price Range field (create a function and apply it to the Price Range column). Examples:\n",
    "#    - '$8.00-$10.00' ‚Üí 9.0  \n",
    "#    - '$5.00' ‚Üí 5.0  \n",
    "#    - '-' ‚Üí None\n",
    "# 4. Convert Shares Offered to numeric, clean missing or invalid values.\n",
    "# 5. Create a new column:  \n",
    "#    Withdrawn Value = Shares Offered * Avg Price (**71 non-null values**)\n",
    "# 6. Group by Company Class and calculate total withdrawn value.\n",
    "# 7. **Answer**: Which class had the highest **total** value of withdrawals?\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# Define the URL and headers to mimic a browser request\n",
    "url = 'https://stockanalysis.com/ipos/withdrawn/'\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \\\n",
    "                   (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Clean and safe way to parse HTML into a DataFrame\n",
    "tables = pd.read_html(StringIO(response.text))\n",
    "df = tables[0]\n",
    "print(f\"‚úÖ Loaded {len(df)} rows.\")\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "print(df.columns.tolist())\n",
    "\n",
    "\n",
    "# %%\n",
    "df['Company Class'] = df['Company Name'].apply(classify_company)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Define function to classify company types based on keywords\n",
    "def classify_company(name):\n",
    "    name = name.lower()\n",
    "    if 'acquisition corp' in name or 'acquisition corporation' in name:\n",
    "        return 'Acq.Corp'\n",
    "    elif 'inc' in name or 'incorporated' in name:\n",
    "        return 'Inc'\n",
    "    elif 'group' in name:\n",
    "        return 'Group'\n",
    "    elif 'ltd' in name or 'limited' in name:\n",
    "        return 'Limited'\n",
    "    elif 'holdings' in name:\n",
    "        return 'Holdings'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply the classification using 'Company Name' column\n",
    "df['Company Class'] = df['Company Name'].apply(classify_company)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Define function to parse and average price ranges\n",
    "def parse_avg_price(price_range):\n",
    "    if price_range == '-' or pd.isna(price_range):\n",
    "        return None\n",
    "    prices = price_range.replace('$', '').split('-')\n",
    "    try:\n",
    "        prices = [float(p) for p in prices]\n",
    "        return sum(prices) / len(prices)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply the function to create a new column\n",
    "df['Avg Price'] = df['Price Range'].apply(parse_avg_price)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Remove commas and convert Shares Offered to numeric\n",
    "df['Shares Offered'] = pd.to_numeric(df['Shares Offered'].str.replace(',', ''), errors='coerce')\n",
    "\n",
    "\n",
    "# %%\n",
    "# Calculate Withdrawn Value as Shares Offered √ó Avg Price\n",
    "df['Withdrawn Value'] = df['Shares Offered'] * df['Avg Price']\n",
    "\n",
    "# Print how many non-null values were successfully calculated\n",
    "print(f\"‚úÖ Non-null Withdrawn Value entries: {df['Withdrawn Value'].notnull().sum()}\")  # Should be 71\n",
    "\n",
    "\n",
    "# %%\n",
    "# Group by Company Class and sum the Withdrawn Value\n",
    "grouped = df.groupby('Company Class')['Withdrawn Value'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Show results\n",
    "print(\"\\nüìä Total Withdrawn IPO Value by Company Class (in millions):\")\n",
    "print(grouped)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Find and print the top class and its total withdrawn value\n",
    "max_class = grouped.idxmax()\n",
    "max_value = grouped.max()\n",
    "print(f\"\\n‚úÖ The company class with the highest total withdrawn value is: {max_class} (${max_value:.2f} million)\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Question 2:   [IPO] Median Sharpe Ratio for 2024 IPOs (First 5 Months)\n",
    "# \n",
    "# \n",
    "# **What is the median Sharpe ratio (as of 6 June 2025) for companies that went public in the first 5 months of 2024?**\n",
    "# \n",
    "# The goal is to replicate the large-scale `yfinance` OHLCV data download and perform basic financial calculations on IPO stocks.\n",
    "# \n",
    "# \n",
    "# #### Steps:\n",
    "# \n",
    "# 1. Using the same approach as in Question 1, download the IPOs in 2024 from:  \n",
    "#    [https://stockanalysis.com/ipos/2024/](https://stockanalysis.com/ipos/2024/)  \n",
    "#    Filter to keep only those IPOs **before 1 June 2024** (first 5 months of 2024).  \n",
    "#    ‚û§ You should have **75 tickers**.\n",
    "# \n",
    "# 2.  Use **Code Snippet 7** to download daily stock data for those tickers (via `yfinance`).  \n",
    "#    Make sure you understand how `growth_1d` ... `growth_365d`, and volatility columns are defined.  \n",
    "#    Define a new column `growth_252d` representing growth after **252 trading days** (~1 year), in addition to any other growth periods you already track.\n",
    "# \n",
    "# \n",
    "# 3. Calculate the Sharpe ratio assuming a risk-free rate of **4.5%**:\n",
    "# \n",
    "#    ```python\n",
    "#    stocks_df['Sharpe'] = (stocks_df['growth_252d'] - 0.045) / stocks_df['volatility']\n",
    "#    ```\n",
    "# \n",
    "#    ‚ö†Ô∏è **IMPORTANT** Please use the original version of annualized volatility calculation (it was later corrected to another formula):\n",
    "#    ```python\n",
    "#    stocks_df['volatility'] =   stocks_df['Close'].rolling(30).std() * np.sqrt(252)\n",
    "#    ```\n",
    "# 4. Filter the DataFrame to keep data only for the trading day:  \n",
    "#    **‚Äò2025-06-06‚Äô**\n",
    "# \n",
    "#    Compute descriptive statistics (e.g., `.describe()`) for these columns:  \n",
    "#    - `growth_252d`  \n",
    "#    - `Sharpe`\n",
    "# \n",
    "#    You should observe:  \n",
    "#    - `growth_252d` is defined for **71 out of 75 stocks** (some IPOs are too recent or data starts later).  \n",
    "#    - Median `growth_252d` is approximately **0.75** (indicating a 25% decline), while mean is about **1.15**, showing a bias towards high-growth companies pushing the average up.\n",
    "# \n",
    "# 5. **Answer:**  \n",
    "#    - What is the **median Sharpe ratio** for these 71 stocks?  \n",
    "#    - Note: Positive `Sharpe` means growth exceeding the risk-free rate of 4.5%.  \n",
    "#    - [Additional] Do you observe the **same top 10 companies** when sorting by `growth_252d` versus sorting by `Sharpe`?\n",
    "# \n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO  # For future compatibility\n",
    "\n",
    "# STEP 1: Scrape IPO list from StockAnalysis.com\n",
    "url = \"https://stockanalysis.com/ipos/2024/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find the HTML table\n",
    "table_html = str(soup.find(\"table\"))\n",
    "\n",
    "# Wrap in StringIO to avoid future warnings\n",
    "df = pd.read_html(StringIO(table_html))[0]\n",
    "\n",
    "# Rename and parse date\n",
    "df.rename(columns={\"IPO Date\": \"Date\"}, inplace=True)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "# Filter IPOs before June 1, 2024\n",
    "df = df[df[\"Date\"] < \"2024-06-01\"]\n",
    "\n",
    "# Clean symbol column\n",
    "df = df[~df[\"Symbol\"].isnull()]\n",
    "df = df[df[\"Symbol\"].str.isupper()]\n",
    "\n",
    "# Extract ticker list\n",
    "ipo_tickers = df[\"Symbol\"].tolist()\n",
    "print(f\"‚úÖ Tickers collected: {len(ipo_tickers)}\")\n",
    "\n",
    "\n",
    "# %%\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "\n",
    "# Initialize list to hold all ticker data\n",
    "all_data = []\n",
    "\n",
    "# Loop through each ticker\n",
    "for i, ticker in enumerate(ipo_tickers):\n",
    "    print(f\"{i+1}/{len(ipo_tickers)}: Downloading {ticker}...\")\n",
    "\n",
    "    try:\n",
    "        # Download 2024-2025 data from Yahoo Finance\n",
    "        df = yf.download(ticker, start=\"2024-01-01\", end=\"2025-06-07\", progress=False)\n",
    "\n",
    "        # Skip if data is empty\n",
    "        if df.empty:\n",
    "            print(f\"‚ö†Ô∏è {ticker}: No data.\")\n",
    "            continue\n",
    "\n",
    "        # Add identifier columns\n",
    "        df[\"Ticker\"] = ticker\n",
    "        df[\"Date\"] = df.index\n",
    "\n",
    "        # Compute 1-year growth (252 trading days)\n",
    "        df[\"growth_252d\"] = df[\"Close\"] / df[\"Close\"].shift(252)\n",
    "\n",
    "        # Compute annualized 30-day rolling volatility\n",
    "        df[\"volatility\"] = df[\"Close\"].rolling(window=30).std() * np.sqrt(252)\n",
    "\n",
    "        # Calculate Sharpe ratio using risk-free rate of 4.5%\n",
    "        df[\"Sharpe\"] = (df[\"growth_252d\"] - 0.045) / df[\"volatility\"]\n",
    "\n",
    "        # Append result to main list\n",
    "        all_data.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error with {ticker}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Combine all ticker data into one DataFrame\n",
    "stocks_df = pd.concat(all_data).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Completed data download for {len(stocks_df['Ticker'].unique())} tickers.\")\n",
    "\n",
    "\n",
    "# %%\n",
    "print(stocks_df.columns.tolist())\n",
    "\n",
    "\n",
    "# %%\n",
    "print(isinstance(stocks_df.columns, pd.MultiIndex))\n",
    "\n",
    "\n",
    "# %%\n",
    "stocks_df.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in stocks_df.columns]\n",
    "\n",
    "\n",
    "# %%\n",
    "print(stocks_df.columns.tolist())\n",
    "\n",
    "\n",
    "# %%\n",
    "stocks_df.rename(columns={\n",
    "    \"Date_\": \"Date\",\n",
    "    \"growth_252d_\": \"growth_252d\",\n",
    "    \"Sharpe_\": \"Sharpe\"\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# %%\n",
    "snapshot = stocks_df[stocks_df[\"Date\"] == \"2025-06-06\"]\n",
    "snapshot = snapshot.dropna(subset=[\"growth_252d\", \"Sharpe\"])\n",
    "\n",
    "print(f\"üìÖ Valid records for 2025-06-06: {len(snapshot)} stocks\")\n",
    "print(snapshot[[\"growth_252d\", \"Sharpe\"]].describe())\n",
    "\n",
    "median_sharpe = snapshot[\"Sharpe\"].median()\n",
    "print(f\"\\nüìå Median Sharpe Ratio (as of 2025-06-06): {median_sharpe:.2f}\")\n",
    "\n",
    "\n",
    "# %%\n",
    "top_growth = snapshot.sort_values(\"growth_252d\", ascending=False).head(10)[\"Ticker_\"].tolist()\n",
    "top_sharpe = snapshot.sort_values(\"Sharpe\", ascending=False).head(10)[\"Ticker_\"].tolist()\n",
    "\n",
    "overlap = set(top_growth) & set(top_sharpe)\n",
    "print(f\"üîÅ Top 10 Overlap: {len(overlap)} tickers ‚Üí {list(overlap)}\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# Sort and get top 10 by growth_252d\n",
    "top_growth_df = snapshot.sort_values(\"growth_252d\", ascending=False).head(10)\n",
    "\n",
    "# Sort and get top 10 by Sharpe\n",
    "top_sharpe_df = snapshot.sort_values(\"Sharpe\", ascending=False).head(10)\n",
    "\n",
    "# Display Top 10 by growth\n",
    "print(\"üèÜ Top 10 IPOs by 1-Year Growth:\\n\")\n",
    "print(top_growth_df[[\"Ticker_\", \"growth_252d\", \"Sharpe\"]].reset_index(drop=True))\n",
    "\n",
    "# Display Top 10 by Sharpe\n",
    "print(\"\\n‚≠ê Top 10 IPOs by Sharpe Ratio:\\n\")\n",
    "print(top_sharpe_df[[\"Ticker_\", \"Sharpe\", \"growth_252d\"]].reset_index(drop=True))\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Question 3: [IPO] ‚ÄòFixed Months Holding Strategy‚Äô\n",
    "# \n",
    "# **What is the optimal number of months (1 to 12) to hold a newly IPO'd stock in order to maximize average growth?**  \n",
    "# (*Assume you buy at the close of the first trading day and sell after a fixed number of trading days.*)\n",
    "# \n",
    "# \n",
    "# ---\n",
    "# \n",
    "# #### Goal:\n",
    "# Investigate whether holding an IPO stock for a fixed number of months after its first trading day produces better returns, using future growth columns.\n",
    "# \n",
    "# ---\n",
    "# \n",
    "# #### Steps:\n",
    "# \n",
    "# 1. **Start from the existing DataFrame** from Question 2 (75 tickers from IPOs in the first 5 months of 2024).  \n",
    "# \n",
    "#    Add **12 new columns**:  \n",
    "#    `future_growth_1m`, `future_growth_2m`, ..., `future_growth_12m`  \n",
    "#    *(Assume 1 month = 21 trading days, so growth is calculated over 21, 42, ..., 252 trading days)*  \n",
    "#    This logic is similar to `historyPrices['growth_future_30d']` from **Code Snippet 7**, but extended to longer timeframes.\n",
    "# \n",
    "# 2. **Determine the first trading day** (`min_date`) for each ticker.  \n",
    "#    This is the earliest date in the data for each stock.\n",
    "# \n",
    "# 3. **Join the data**:  \n",
    "#    Perform an **inner join** between the `min_date` DataFrame and the future growth data on both `ticker` and `date`.  \n",
    "#    ‚û§ You should end up with **75 records** (one per IPO) with all 12 `future_growth_...` fields populated.\n",
    "# \n",
    "# 4. **Compute descriptive statistics** for the resulting DataFrame:  \n",
    "#    Use `.describe()` or similar to analyze each of the 12 columns:  \n",
    "#    - `future_growth_1m`  \n",
    "#    - `future_growth_2m`  \n",
    "#    - ...  \n",
    "#    - `future_growth_12m`  \n",
    "# \n",
    "# 5. **Determine the best holding period**:  \n",
    "#    - Find the number of months **(1 to 12)** where the **average (mean)** future growth is **maximal**.  \n",
    "#    - This optimal month shows an uplift of **>1%** compared to all others.  \n",
    "#    - Still, the average return remains **less than 1** (i.e., expected return is less than doubling your investment).\n",
    "# \n",
    "# \n",
    "\n",
    "# %%\n",
    "# Create a fresh list to hold data per ticker\n",
    "growth_frames = []\n",
    "\n",
    "# Loop through each unique ticker\n",
    "for ticker in stocks_df[\"Ticker_\"].unique():\n",
    "    df = stocks_df[stocks_df[\"Ticker_\"] == ticker].copy()\n",
    "\n",
    "    # Skip tickers without Close_<ticker> column\n",
    "    close_col = f\"Close_{ticker}\"\n",
    "    if close_col not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è Skipping {ticker}: No '{close_col}' found.\")\n",
    "        continue\n",
    "\n",
    "    # Base closing price\n",
    "    close = df[close_col]\n",
    "\n",
    "    # Add future growth columns: 1m (21d), 2m (42d), ..., 12m (252d)\n",
    "    for m in range(1, 13):\n",
    "        days = m * 21\n",
    "        df[f\"future_growth_{m}m\"] = close.shift(-days) / close\n",
    "\n",
    "    # Keep only first trading day\n",
    "    first_row = df.sort_values(\"Date\").iloc[[0]]\n",
    "    growth_frames.append(first_row)\n",
    "\n",
    "# Combine all first-day records into one DataFrame\n",
    "first_day_growth_df = pd.concat(growth_frames).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Columns for analysis\n",
    "future_cols = [f\"future_growth_{m}m\" for m in range(1, 13)]\n",
    "\n",
    "# Descriptive statistics\n",
    "stats = first_day_growth_df[future_cols].describe().T\n",
    "stats[\"mean_growth\"] = first_day_growth_df[future_cols].mean().values\n",
    "\n",
    "# Print summary\n",
    "print(stats[[\"mean\", \"std\", \"mean_growth\"]])\n",
    "\n",
    "# Find best holding period\n",
    "best_month = stats[\"mean_growth\"].idxmax()\n",
    "best_return = stats[\"mean_growth\"].max()\n",
    "print(f\"\\nüìà Best holding period: {best_month} ‚Üí Avg growth: {best_return:.2f}\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Question 4: [Strategy] Simple RSI-Based Trading Strategy\n",
    "# \n",
    "# \n",
    "# **What is the total profit (in $thousands) you would have earned by investing $1000 every time a stock was oversold (RSI < 25)?**\n",
    "# \n",
    "# \n",
    "# ---\n",
    "# \n",
    "# #### Goal:\n",
    "# Apply a simple rule-based trading strategy using the **Relative Strength Index (RSI)** technical indicator to identify oversold signals and calculate profits.\n",
    "# \n",
    "# ---\n",
    "# \n",
    "# \n",
    "# #### Steps:\n",
    "# \n",
    "# 1. **Run the full notebook from Lecture 2 (33 stocks)**  \n",
    "#    - Ensure you can generate the merged DataFrame containing:  \n",
    "#      - OHLCV data  \n",
    "#      - Technical indicators  \n",
    "#      - Macro indicators  \n",
    "#    - Focus on getting **RSI** computed using **Code Snippets 8 and 9**.  \n",
    "#    - This process is essential and will help during the capstone project.\n",
    "# \n",
    "# 2. ‚ö†Ô∏è **IMPORTANT** Please use this file to solve the Home Assignment (**all next steps**)\n",
    "#  \n",
    "#    Download precomputed data using this snippet:\n",
    "# \n",
    "#    ```python\n",
    "#    import gdown\n",
    "#    import pandas as pd\n",
    "# \n",
    "#    file_id = \"1grCTCzMZKY5sJRtdbLVCXg8JXA8VPyg-\"\n",
    "#    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", \"data.parquet\", quiet=False)\n",
    "#    df = pd.read_parquet(\"data.parquet\", engine=\"pyarrow\")\n",
    "# \n",
    "# 3. **RSI Strategy Setup:**  \n",
    "#    - RSI is already available in the dataset as a field.  \n",
    "#    - The threshold for **oversold** is defined as `RSI < 25`.\n",
    "# \n",
    "# 4. **Filter the dataset by RSI and date:**  \n",
    "#    ```python\n",
    "#    rsi_threshold = 25\n",
    "#    selected_df = df[\n",
    "#        (df['rsi'] < rsi_threshold) &\n",
    "#        (df['Date'] >= '2000-01-01') &\n",
    "#        (df['Date'] <= '2025-06-01')\n",
    "#    ]\n",
    "# 5. **Calculate Net Profit Over 25 Years:**  \n",
    "#    - Total number of trades: **1568**  \n",
    "#    - For each trade, you invest **$1000**  \n",
    "#    - Use the 30-day forward return (`growth_future_30d`) to compute net earnings:  \n",
    "#      ```python\n",
    "#      net_income = 1000 * (selected_df['growth_future_30d'] - 1).sum()\n",
    "#      ```\n",
    "# \n",
    "#    - **Final Answer:**  \n",
    "#      What is the **net income in $K** (i.e., in thousands of dollars) that could be earned using this RSI-based oversold strategy from 2000‚Äì2025?\n",
    "# \n",
    "# \n",
    "\n",
    "# %%\n",
    "pip install pyarrow\n",
    "\n",
    "\n",
    "# %%\n",
    "print(df.columns.tolist())\n",
    "\n",
    "\n",
    "# %%\n",
    "pip install ta\n",
    "\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import ta\n",
    "\n",
    "# Load your parquet file\n",
    "df = pd.read_parquet(\"C:/Users/rahul/stock-markets-analytics-zoomcamp/02-dataframe-analysis/stocks_df_combined_2025_06_20.parquet.brotli\", engine=\"pyarrow\")\n",
    "\n",
    "# Compute RSI for AAPL\n",
    "df = df.sort_values(\"Date\")\n",
    "df[\"rsi_AAPL\"] = ta.momentum.RSIIndicator(close=df[\"Close_AAPL\"], window=14).rsi()\n",
    "\n",
    "# 30-day future return\n",
    "df[\"growth_future_30d_AAPL\"] = df[\"Close_AAPL\"].shift(-30) / df[\"Close_AAPL\"]\n",
    "\n",
    "# Filter RSI < 25 and date range\n",
    "selected = df[\n",
    "    (df[\"rsi_AAPL\"] < 25) &\n",
    "    (df[\"Date\"] >= \"2000-01-01\") &\n",
    "    (df[\"Date\"] <= \"2025-06-01\")\n",
    "]\n",
    "\n",
    "# Calculate total net income from $1000 per trade\n",
    "net_income = 1000 * (selected[\"growth_future_30d_AAPL\"] - 1).sum()\n",
    "print(f\"üìà Total net income from RSI strategy on AAPL: ${net_income / 1000:.2f}K\")\n",
    "\n",
    "\n",
    "# %%\n",
    "pip install gdown\n",
    "\n",
    "\n",
    "# %%\n",
    "import gdown\n",
    "import pandas as pd\n",
    "\n",
    "# Download the assignment dataset\n",
    "file_id = \"1grCTCzMZKY5sJRtdbLVCXg8JXA8VPyg-\"\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", \"data.parquet\", quiet=False)\n",
    "\n",
    "# Load it\n",
    "df = pd.read_parquet(\"data.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"data.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "selected_df = df[\n",
    "    (df['rsi'] < 25) &\n",
    "    (df['Date'] >= '2000-01-01') &\n",
    "    (df['Date'] <= '2025-06-01')\n",
    "]\n",
    "\n",
    "net_income = 1000 * (selected_df['growth_future_30d'] - 1).sum()\n",
    "print(f\"üìå Net income from RSI strategy: ${net_income / 1000:.2f}K\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# Question 5. Q5. [Exploratory, Optional] Predicting a Positive-Return IPO (1 point)\n",
    "\n",
    "# %% [markdown]\n",
    "# To predict whether an IPO will yield a positive 1-year return, we can use a combination of price-based, company-level, technical, and macroeconomic features. Early performance indicators like first-day return, short-term volatility, and momentum (e.g., 30-day or 90-day growth) offer strong signals. Metadata such as the sector, IPO month, and exchange listing may capture structural or seasonal patterns. Technical indicators like RSI, MACD, and moving average crossovers help identify early price momentum or reversals. Finally, market conditions‚Äîsuch as S&P 500 trends, VIX levels, or interest rates‚Äîprovide useful context about the broader economic environment at IPO time.\n",
    "\n",
    "# %% [markdown]\n",
    "# Classification problem with a Target: growth_252d > 1  ‚Üí \"Positive Return\"\n",
    "# \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
